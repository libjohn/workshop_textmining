{
  "hash": "e858fb8fd43b2c98d8d875c169a45ecd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercise 1. Your turn\"\n---\n\n\n## Load library packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janeaustenr)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'dplyr' was built under R version 4.3.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.3.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidytext' was built under R version 4.3.2\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(wordcloud2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'wordcloud2' was built under R version 4.3.2\n```\n\n\n:::\n:::\n\n\n## Your Turn. Exercise 1.\n\nGoal: Make a basic word cloud for the novel, *Pride and Predjudice*, `pride_prej_novel`\n\na.  Prepare: Add a line number to the text\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_prej_novel <-  tibble(text = prideprejudice) %>%\n  mutate(line = ________________)\n```\n:::\n\n\nb.  Tokenize `pride_prej_novel` with `unnest_tokens()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_prej_novel %>% \n  unnest_tokens(____, _____)\n```\n:::\n\n\nc.  Remove stop-words\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_prej_novel %>% \n  unnest_tokens(____, _____) %>% \n  anti_join(____________)\n```\n:::\n\n\nd.  calculate word frequency\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_prej_novel %>% \n  unnest_tokens(____, _____) %>% \n  anti_join(____________) %>% \n  count(____________) \n```\n:::\n\n\ne.  make a simple wordcloud\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_prej_novel %>% \n  unnest_tokens(____, _____) %>% \n  anti_join(____________) %>% \n  count(____________)  %>% \n  with(wordcloud::wordcloud(____, ____, max.words = ___))\n```\n:::\n\n\nf.  Since \"Friends don't let friends make word clouds\", make a barplot of the word frequency.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_prej_novel %>% \n  unnest_tokens(word, text) %>% \n  anti_join(get_stopwords(), by = \"word\") %>% \n  count(word, sort = TRUE) %>% \n  slice_head(n = 10) %>% \n  ggplot(aes(x = n, y = fct_reorder(word, n))) +\n  geom_col() +\n  labs(title = \"Word Frequency\",\n       subtitle = \"Jane Austen novel\",\n       x = \"\", y = \"\",\n       caption = \"Source: janeaustenr\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}