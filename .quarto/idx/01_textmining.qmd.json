{"title":"Sentiment Analysis","markdown":{"yaml":{"title":"Sentiment Analysis","author":[{"name":"John R Little","affiliations":[{"name":"Duke University"},{"department":"Center for Data & Vizualization Sciences"}]}],"date-modified":"today","date-format":"long","format":{"html":{"embed-resources":true,"footer":"[John R Little](https://JohnLittle.info) ● [Center for Data & Visualization Sciences](https://library.duke.edu/data/) ● [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)","logo":"images/Rfun_logo.png","license":"CC BY","toc":true,"toc_float":true,"df-print":"paged"}}},"headingText":"Data","containsRefs":false,"markdown":"\n\nFind this repository: https://github.com/libjohn/workshop_textmining\n\nMuch of this review comes from the site: https://juliasilge.github.io/tidytext/\n\nThe primary library package `tidytext` enables all kinds of text mining. See Also this helpful free online book: [Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) by Silge and Robinson\n\n```{r}\nlibrary(janeaustenr)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(wordcloud2)\nlibrary(textdata)\n```\n\n```{r}\n#| echo: false\nhtmltools::img(src = knitr::image_uri(here::here(\"images\", \"Rfun_logo.png\")),\nalt = 'Rfun',\nstyle = 'position:absolute; bottom:15px; left:0; padding:5px; border:0px;')\n\nhtmltools::img(src = knitr::image_uri(here::here(\"images\", \"CDVS-logo_sm_Spring2020.png\")),\nalt = 'Rfun',\nstyle = 'position:absolute; bottom:0; right:0; padding:5px; border:0px;')\n```\n\n\nWe'll look at some books by [Jane Austen](https://en.wikipedia.org/wiki/Jane_Austen), an 18th century novelist. Austen explored women and marriage within the British upper class. The novelist has a unique and well earned following within literature. Her works is consistently discussed and honored. To this day, Austen's novels are the source of many adaptations, written and on-screen. Through the `janeaustenr` package we can access and mine the text of six Austen novels. We can call the collection of novels a corpra. An individual novel is a corpus.\n\n```{r}\nausten_books()\n```\n\nAusten is best know for six published works:\n\n```{r}\nausten_books() %>% \n  distinct(book)\n```\n\n## Data Cleaning\n\nText mining typically requires a lot of data cleaning. In this case, we start with the `janeaustenr` collection that has already been cleaned. Nonetheless, further data wrangling is required. First, identifying a line number for each line of text in each book.\n\n## Identify line numbers\n\n```{r}\noriginal_books <- austen_books() %>%\n  group_by(book) %>%\n  mutate(line = row_number()) %>%         # identify line numbers\n  ungroup()\n\noriginal_books\n```\n\n## Tokens\n\nTo work with these data as a **tidy** dataset, we need to restructure the data through *tokenization*. In our case a token is a single word. We want **one-token-per-row**. The `unnest_tokens()` function (tidytext package) will convert a data frame with a text column into the one-token-per-row format.\n\n**Token**\\\n**Tokenization**\\\n[defined](https://www.techopedia.com/definition/13698/tokenization)\n\nThe default tokenizing mode is \"words\". With the `unnest_tokens()` function, tokens can be: **words**, characters, character_shingles, **ngrams**, skip_ngrams, **sentences**, lines, paragraphs, regex, tweets, and ptb (Penn Treebank).\n\n### Process\n\n1.  Group by **line number** (above)\n2.  Make each single word a token\n\n```{r}\ntidy_books <- original_books %>%\n  unnest_tokens(word, text)\n\ntidy_books\n```\n\n> Now that the data is in the one-word-per-row format, we can manipulate it with tidy tools like dplyr.\n\n## Stop Words\n\n`tidytext::get_stopwords()`\n\nRemove stop-words from the books.\n\n```{r}\nmatchwords_books <- tidy_books %>%\n  anti_join(get_stopwords())\n\nmatchwords_books\n```\n\n### Join types\n\n![](https://pbs.twimg.com/media/B6eUTTACUAAahLf.png \"Dplyr Join Diagram\")\n\n### Customize your dictionaries\n\nYou can customize stop-words data frames, sentiment data frames, etc.\n\nThere are various *stop words* dictionaries. Here we add the stop word, \"farfegnugen\" to a custom dictionary. If Jane Austen ever used the word \"farfegnugen\" that would be weird, or bad. So we will take pains to not calculate the sentiment of that word - whether or not the term shows up in a sentiment dictionary. That is, we will remove the word by making it a part of a customized stop-words dictionary.\n\n```{r}\nstopwords::stopwords_getsources()\nstopwords::stopwords_getlanguages(\"snowball\")\n\nstopwords_custom <- tribble(~word, ~lexicon,\n                            \"farfegnugen\", \"custom\")\n\nstopwords_custom\n\nget_stopwords(source = \"snowball\")\n\nbind_rows(get_stopwords(), stopwords_custom)    # The default is \"snowball\"\n\n```\n\n### Calculate word frequency\n\nHow many Austen countable words are there if we remove *snowball* stop-words? There are `r   nrow(dplyr::distinct(matchwords_books, word))` countable words.\n\n```{r}\nmatchwords_books %>% \n  # distinct(word)\n  count(word, sort = TRUE) \n```\n\n## Word clouds\n\n```{r interactive word cloud, fig.width=10}\nmatchwords_books %>%\n  count(word, sort = TRUE) %>%\n  head(100) %>% \n  wordcloud2(size = .4, shape = 'triangle-forward', \n             color = c(\"steelblue\", \"firebrick\", \"darkorchid\"), \n             backgroundColor = \"salmon\")\n\n```\n\n### Basic word cloud\n\nA non-interactive word cloud.\n\n```{r basic word cloud, fig.height=8, fig.width=8}\nmatchwords_books %>%\n  count(word) %>%\n  with(wordcloud::wordcloud(word, n, max.words = 100))\n```\n\n## Your Turn: Exercise 1\n\nGoal: Make a basic word cloud for the novel, *Pride and Predjudice*, `pride_prej_novel`\n\na.  Prepare\n\n```{r}\npride_prej_novel <- tibble(text = prideprejudice) %>% \n  mutate(line = row_number())\n```\n\nb.  Tokenize `pride_prej_novel` with `unnest_tokens()`\n\n```{r}\n\n```\n\nc.  Remove stop-words\n\n```{r}\n\n```\n\nd.  calculate word frequency\n\n```{r}\n\n```\n\ne.  make a simple wordcloud\n\n```{r}\n\n```\n\n## Sentiment Analysis\n\n`get_sentiments()`\n\nLet's see what positive words exist in the bing dictionary. Then, count the frequency of those positive words that exist in *Emma*.\n\n```{r}\npositive <- get_sentiments(\"bing\") %>%\n  filter(sentiment == \"positive\")                    # get POSITIVE words\n\npositive \n\ntidy_books %>%\n  filter(book == \"Emma\") %>%                        # only the book _emma_\n  semi_join(positive) %>%                           # semi_join()\n  count(word, sort = TRUE)\n```\n\n### Prepare to visualize sentiment score\n\nMatch all the Austen books to the bing sentiment dictionary. Count the word frequency.\n\n```{r}\ntidy_books %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(book)\n```\n\n### Calculate sentiment\n\n> **Algorithm:** sentiment = positive - negative\n\nDefine a section of text.\n\n> \"Small sections of text may not have enough words in them to get a good estimate of sentiment while really large sections can wash out narrative structure. For these books, using 80 lines works well, but this can vary depending on individual texts... -- [Text Mining with R](https://www.tidytextmining.com/sentiment.html)\n\n```{r echo=TRUE}\nbing <- get_sentiments(\"bing\")\n\njaneaustensentiment <- tidy_books %>% \n  inner_join(bing) %>% \n  count(book, index = line %/% 80, sentiment) %>%                          # `%/%` = int division ; 80 lines / section\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%    # spread(sentiment, n, fill = 0)\n  mutate(sentiment = positive - negative)                                      # ALGO!!!\n  \njaneaustensentiment\n```\n\n### Viz it\n\n```{r sentiment score}\njaneaustensentiment %>%\n  ggplot(aes(index, sentiment, )) +\n  geom_col(show.legend = FALSE, fill = \"cadetblue\") +\n  geom_col(data = . %>% filter(sentiment < 0), show.legend = FALSE, fill = \"firebrick\") +\n  geom_hline(yintercept = 0, color = \"goldenrod\") +\n  facet_wrap(~ book, ncol = 2, scales = \"free_x\") \n```\n\n### Preparation: Most common positive and negative words\n\n```{r}\nbing_word_counts <- tidy_books %>%\n  inner_join(bing) %>%\n  count(word, sentiment, sort = TRUE)\n\nbing_word_counts\n```\n\n### Viz it too\n\n```{r positive and negative, fig.height=7, fig.width=10}\nbing_word_counts %>%\n  filter(n > 170) %>%\n  mutate(n = if_else(sentiment == \"negative\", - n, n)) %>%\n  ggplot(aes(fct_reorder(str_to_title(word), n), n, fill = str_to_title(sentiment))) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_brewer(type = \"qual\") +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(title = \"Frequency of popular positive and negative words\",\n       subtitle = \"Jane Austen novels\",\n       y = \"Compound sentiment score\", x = \"\",\n       fill = \"Sentiment\", caption = \"Source: library(janeaustenr)\") +\n  theme(plot.title.position = \"plot\")\n```\n\n## Dictionaries\n\nWhat other dictionaries are available? How to choose?\n\n-   [Without Dictiionaries there is no sentiment analysis](http://www.thinkingondata.com/without-dictionaries-no-sentiment-analysis/)\n-   [Sentiment Analysis: Analyzing Lexicon Quality and Estimation Errors](https://paulvanderlaken.com/2017/12/27/sentiment-analysis-lexicon-quality/)\n-   [Limits of the Bing, AFINN, and NRC Lexicons with the Tidytext Package in R](https://hoyeolkim.wordpress.com/2018/02/25/the-limits-of-the-bing-afinn-and-nrc-lexicons-with-the-tidytext-package-in-r/)\n-   [Case Study with Harry Potter](https://afit-r.github.io/sentiment_analysis)\n\n```{r}\nhead(get_sentiments(\"bing\"))\nhead(get_sentiments(\"loughran\"))\nhead(get_sentiments(\"nrc\"))\nhead(get_sentiments(\"afinn\"))\n\nget_sentiments(\"nrc\") %>% \n  count(sentiment, sort = TRUE) \n\n```\n\n## Afinn\n\nWhat words in *Emma* match the AFINN dictionary?\n\n```{r}\nemma_afinn <- tidy_books %>%\n  filter(book == \"Emma\") %>% \n  anti_join(get_stopwords()) %>% \n  inner_join(get_sentiments(\"afinn\"))\n\nemma_afinn\n```\n\n```{r}\nemma_afinn %>% \n  count(word, sort = TRUE)\n```\n\n### Make Sections\n\nJust as we calculated sentiment, above, make sections of 80 words then calculate sentiment.\n\n```{r}\nemma_afinn_sentiment <- emma_afinn %>% \n  mutate(word_count = 1:n(),\n         index = word_count %/% 80) %>% \n  group_by(index) %>% \n  summarise(sentiment = sum(value))           ## ALGO sum each Afinn score in the 80 word section\n\nemma_afinn_sentiment\n\n```\n\n### Viz it\n\n```{r emma word cloud}\nemma_afinn %>% \n  mutate(word_count = 1:n(),\n         index = word_count %/% 80) %>% \n  filter(index == 104) %>%\n  count(word, sort = TRUE) %>%\n  with(wordcloud::wordcloud(word, n, \n                            rot.per = .3))\n\nemma_afinn %>% \n  mutate(word_count = 1:n(),\n         index = word_count %/% 80) %>% \n  filter(index == 104) %>%\n  count(word, sort = TRUE) %>%\n  wordcloud2(size = .4, shape = 'diamond',\n             backgroundColor = \"darkseagreen\")\n\n```\n\n```{r emma afinn}\nemma_afinn_sentiment %>% \n  ggplot(aes(index, sentiment)) +\n  geom_col(aes(fill = cut_interval(sentiment, n = 5))) +\n  geom_hline(yintercept = 0, color = \"forestgreen\", linetype = \"dashed\") +\n  scale_fill_brewer(palette = \"RdBu\", guide = FALSE) +\n  theme(panel.background = element_rect(fill = \"grey\"),\n        plot.background = element_rect(fill = \"grey\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Afinn Sentiment Analysis of _Emma_\")\n```\n\n```{r emma boxplot of afinn}\nemma_afinn %>%\n  mutate(word_count = 1:n(),\n         index = as.character(word_count %/% 80)) %>%\n  filter(index == 10 | index == 104 | index == 105) %>% \n  ggplot(aes(value, index)) +\n  geom_boxplot() +\n  # geom_boxplot(notch = TRUE) +\n  geom_jitter() +\n  coord_flip() +\n  labs(y = \"section\", x = \"Afinn\")\n```\n\n## Resources\n\n-   [Tidytext package](https://juliasilge.github.io/tidytext/)\n-   Book: [Text Mining with R](https://www.tidytextmining.com/) by Silge and Robinson\n-   Data Wrangling with dplyr: ([video](https://juliasilge.github.io/tidytext/) \\| [workshop](https://rfun.library.duke.edu/portfolio/r_flipped/))\n-   Data Visualization with ggplot2: ([video](https://warpwire.duke.edu/w/80YEAA/) \\| [workshop](https://rfun.library.duke.edu/portfolio/ggplot_workshop/))\n\n \n\n \n","srcMarkdownNoYaml":"\n\nFind this repository: https://github.com/libjohn/workshop_textmining\n\nMuch of this review comes from the site: https://juliasilge.github.io/tidytext/\n\nThe primary library package `tidytext` enables all kinds of text mining. See Also this helpful free online book: [Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) by Silge and Robinson\n\n```{r}\nlibrary(janeaustenr)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(wordcloud2)\nlibrary(textdata)\n```\n\n```{r}\n#| echo: false\nhtmltools::img(src = knitr::image_uri(here::here(\"images\", \"Rfun_logo.png\")),\nalt = 'Rfun',\nstyle = 'position:absolute; bottom:15px; left:0; padding:5px; border:0px;')\n\nhtmltools::img(src = knitr::image_uri(here::here(\"images\", \"CDVS-logo_sm_Spring2020.png\")),\nalt = 'Rfun',\nstyle = 'position:absolute; bottom:0; right:0; padding:5px; border:0px;')\n```\n\n## Data\n\nWe'll look at some books by [Jane Austen](https://en.wikipedia.org/wiki/Jane_Austen), an 18th century novelist. Austen explored women and marriage within the British upper class. The novelist has a unique and well earned following within literature. Her works is consistently discussed and honored. To this day, Austen's novels are the source of many adaptations, written and on-screen. Through the `janeaustenr` package we can access and mine the text of six Austen novels. We can call the collection of novels a corpra. An individual novel is a corpus.\n\n```{r}\nausten_books()\n```\n\nAusten is best know for six published works:\n\n```{r}\nausten_books() %>% \n  distinct(book)\n```\n\n## Data Cleaning\n\nText mining typically requires a lot of data cleaning. In this case, we start with the `janeaustenr` collection that has already been cleaned. Nonetheless, further data wrangling is required. First, identifying a line number for each line of text in each book.\n\n## Identify line numbers\n\n```{r}\noriginal_books <- austen_books() %>%\n  group_by(book) %>%\n  mutate(line = row_number()) %>%         # identify line numbers\n  ungroup()\n\noriginal_books\n```\n\n## Tokens\n\nTo work with these data as a **tidy** dataset, we need to restructure the data through *tokenization*. In our case a token is a single word. We want **one-token-per-row**. The `unnest_tokens()` function (tidytext package) will convert a data frame with a text column into the one-token-per-row format.\n\n**Token**\\\n**Tokenization**\\\n[defined](https://www.techopedia.com/definition/13698/tokenization)\n\nThe default tokenizing mode is \"words\". With the `unnest_tokens()` function, tokens can be: **words**, characters, character_shingles, **ngrams**, skip_ngrams, **sentences**, lines, paragraphs, regex, tweets, and ptb (Penn Treebank).\n\n### Process\n\n1.  Group by **line number** (above)\n2.  Make each single word a token\n\n```{r}\ntidy_books <- original_books %>%\n  unnest_tokens(word, text)\n\ntidy_books\n```\n\n> Now that the data is in the one-word-per-row format, we can manipulate it with tidy tools like dplyr.\n\n## Stop Words\n\n`tidytext::get_stopwords()`\n\nRemove stop-words from the books.\n\n```{r}\nmatchwords_books <- tidy_books %>%\n  anti_join(get_stopwords())\n\nmatchwords_books\n```\n\n### Join types\n\n![](https://pbs.twimg.com/media/B6eUTTACUAAahLf.png \"Dplyr Join Diagram\")\n\n### Customize your dictionaries\n\nYou can customize stop-words data frames, sentiment data frames, etc.\n\nThere are various *stop words* dictionaries. Here we add the stop word, \"farfegnugen\" to a custom dictionary. If Jane Austen ever used the word \"farfegnugen\" that would be weird, or bad. So we will take pains to not calculate the sentiment of that word - whether or not the term shows up in a sentiment dictionary. That is, we will remove the word by making it a part of a customized stop-words dictionary.\n\n```{r}\nstopwords::stopwords_getsources()\nstopwords::stopwords_getlanguages(\"snowball\")\n\nstopwords_custom <- tribble(~word, ~lexicon,\n                            \"farfegnugen\", \"custom\")\n\nstopwords_custom\n\nget_stopwords(source = \"snowball\")\n\nbind_rows(get_stopwords(), stopwords_custom)    # The default is \"snowball\"\n\n```\n\n### Calculate word frequency\n\nHow many Austen countable words are there if we remove *snowball* stop-words? There are `r   nrow(dplyr::distinct(matchwords_books, word))` countable words.\n\n```{r}\nmatchwords_books %>% \n  # distinct(word)\n  count(word, sort = TRUE) \n```\n\n## Word clouds\n\n```{r interactive word cloud, fig.width=10}\nmatchwords_books %>%\n  count(word, sort = TRUE) %>%\n  head(100) %>% \n  wordcloud2(size = .4, shape = 'triangle-forward', \n             color = c(\"steelblue\", \"firebrick\", \"darkorchid\"), \n             backgroundColor = \"salmon\")\n\n```\n\n### Basic word cloud\n\nA non-interactive word cloud.\n\n```{r basic word cloud, fig.height=8, fig.width=8}\nmatchwords_books %>%\n  count(word) %>%\n  with(wordcloud::wordcloud(word, n, max.words = 100))\n```\n\n## Your Turn: Exercise 1\n\nGoal: Make a basic word cloud for the novel, *Pride and Predjudice*, `pride_prej_novel`\n\na.  Prepare\n\n```{r}\npride_prej_novel <- tibble(text = prideprejudice) %>% \n  mutate(line = row_number())\n```\n\nb.  Tokenize `pride_prej_novel` with `unnest_tokens()`\n\n```{r}\n\n```\n\nc.  Remove stop-words\n\n```{r}\n\n```\n\nd.  calculate word frequency\n\n```{r}\n\n```\n\ne.  make a simple wordcloud\n\n```{r}\n\n```\n\n## Sentiment Analysis\n\n`get_sentiments()`\n\nLet's see what positive words exist in the bing dictionary. Then, count the frequency of those positive words that exist in *Emma*.\n\n```{r}\npositive <- get_sentiments(\"bing\") %>%\n  filter(sentiment == \"positive\")                    # get POSITIVE words\n\npositive \n\ntidy_books %>%\n  filter(book == \"Emma\") %>%                        # only the book _emma_\n  semi_join(positive) %>%                           # semi_join()\n  count(word, sort = TRUE)\n```\n\n### Prepare to visualize sentiment score\n\nMatch all the Austen books to the bing sentiment dictionary. Count the word frequency.\n\n```{r}\ntidy_books %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(book)\n```\n\n### Calculate sentiment\n\n> **Algorithm:** sentiment = positive - negative\n\nDefine a section of text.\n\n> \"Small sections of text may not have enough words in them to get a good estimate of sentiment while really large sections can wash out narrative structure. For these books, using 80 lines works well, but this can vary depending on individual texts... -- [Text Mining with R](https://www.tidytextmining.com/sentiment.html)\n\n```{r echo=TRUE}\nbing <- get_sentiments(\"bing\")\n\njaneaustensentiment <- tidy_books %>% \n  inner_join(bing) %>% \n  count(book, index = line %/% 80, sentiment) %>%                          # `%/%` = int division ; 80 lines / section\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%    # spread(sentiment, n, fill = 0)\n  mutate(sentiment = positive - negative)                                      # ALGO!!!\n  \njaneaustensentiment\n```\n\n### Viz it\n\n```{r sentiment score}\njaneaustensentiment %>%\n  ggplot(aes(index, sentiment, )) +\n  geom_col(show.legend = FALSE, fill = \"cadetblue\") +\n  geom_col(data = . %>% filter(sentiment < 0), show.legend = FALSE, fill = \"firebrick\") +\n  geom_hline(yintercept = 0, color = \"goldenrod\") +\n  facet_wrap(~ book, ncol = 2, scales = \"free_x\") \n```\n\n### Preparation: Most common positive and negative words\n\n```{r}\nbing_word_counts <- tidy_books %>%\n  inner_join(bing) %>%\n  count(word, sentiment, sort = TRUE)\n\nbing_word_counts\n```\n\n### Viz it too\n\n```{r positive and negative, fig.height=7, fig.width=10}\nbing_word_counts %>%\n  filter(n > 170) %>%\n  mutate(n = if_else(sentiment == \"negative\", - n, n)) %>%\n  ggplot(aes(fct_reorder(str_to_title(word), n), n, fill = str_to_title(sentiment))) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_brewer(type = \"qual\") +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(title = \"Frequency of popular positive and negative words\",\n       subtitle = \"Jane Austen novels\",\n       y = \"Compound sentiment score\", x = \"\",\n       fill = \"Sentiment\", caption = \"Source: library(janeaustenr)\") +\n  theme(plot.title.position = \"plot\")\n```\n\n## Dictionaries\n\nWhat other dictionaries are available? How to choose?\n\n-   [Without Dictiionaries there is no sentiment analysis](http://www.thinkingondata.com/without-dictionaries-no-sentiment-analysis/)\n-   [Sentiment Analysis: Analyzing Lexicon Quality and Estimation Errors](https://paulvanderlaken.com/2017/12/27/sentiment-analysis-lexicon-quality/)\n-   [Limits of the Bing, AFINN, and NRC Lexicons with the Tidytext Package in R](https://hoyeolkim.wordpress.com/2018/02/25/the-limits-of-the-bing-afinn-and-nrc-lexicons-with-the-tidytext-package-in-r/)\n-   [Case Study with Harry Potter](https://afit-r.github.io/sentiment_analysis)\n\n```{r}\nhead(get_sentiments(\"bing\"))\nhead(get_sentiments(\"loughran\"))\nhead(get_sentiments(\"nrc\"))\nhead(get_sentiments(\"afinn\"))\n\nget_sentiments(\"nrc\") %>% \n  count(sentiment, sort = TRUE) \n\n```\n\n## Afinn\n\nWhat words in *Emma* match the AFINN dictionary?\n\n```{r}\nemma_afinn <- tidy_books %>%\n  filter(book == \"Emma\") %>% \n  anti_join(get_stopwords()) %>% \n  inner_join(get_sentiments(\"afinn\"))\n\nemma_afinn\n```\n\n```{r}\nemma_afinn %>% \n  count(word, sort = TRUE)\n```\n\n### Make Sections\n\nJust as we calculated sentiment, above, make sections of 80 words then calculate sentiment.\n\n```{r}\nemma_afinn_sentiment <- emma_afinn %>% \n  mutate(word_count = 1:n(),\n         index = word_count %/% 80) %>% \n  group_by(index) %>% \n  summarise(sentiment = sum(value))           ## ALGO sum each Afinn score in the 80 word section\n\nemma_afinn_sentiment\n\n```\n\n### Viz it\n\n```{r emma word cloud}\nemma_afinn %>% \n  mutate(word_count = 1:n(),\n         index = word_count %/% 80) %>% \n  filter(index == 104) %>%\n  count(word, sort = TRUE) %>%\n  with(wordcloud::wordcloud(word, n, \n                            rot.per = .3))\n\nemma_afinn %>% \n  mutate(word_count = 1:n(),\n         index = word_count %/% 80) %>% \n  filter(index == 104) %>%\n  count(word, sort = TRUE) %>%\n  wordcloud2(size = .4, shape = 'diamond',\n             backgroundColor = \"darkseagreen\")\n\n```\n\n```{r emma afinn}\nemma_afinn_sentiment %>% \n  ggplot(aes(index, sentiment)) +\n  geom_col(aes(fill = cut_interval(sentiment, n = 5))) +\n  geom_hline(yintercept = 0, color = \"forestgreen\", linetype = \"dashed\") +\n  scale_fill_brewer(palette = \"RdBu\", guide = FALSE) +\n  theme(panel.background = element_rect(fill = \"grey\"),\n        plot.background = element_rect(fill = \"grey\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Afinn Sentiment Analysis of _Emma_\")\n```\n\n```{r emma boxplot of afinn}\nemma_afinn %>%\n  mutate(word_count = 1:n(),\n         index = as.character(word_count %/% 80)) %>%\n  filter(index == 10 | index == 104 | index == 105) %>% \n  ggplot(aes(value, index)) +\n  geom_boxplot() +\n  # geom_boxplot(notch = TRUE) +\n  geom_jitter() +\n  coord_flip() +\n  labs(y = \"section\", x = \"Afinn\")\n```\n\n## Resources\n\n-   [Tidytext package](https://juliasilge.github.io/tidytext/)\n-   Book: [Text Mining with R](https://www.tidytextmining.com/) by Silge and Robinson\n-   Data Wrangling with dplyr: ([video](https://juliasilge.github.io/tidytext/) \\| [workshop](https://rfun.library.duke.edu/portfolio/r_flipped/))\n-   Data Visualization with ggplot2: ([video](https://warpwire.duke.edu/w/80YEAA/) \\| [workshop](https://rfun.library.duke.edu/portfolio/ggplot_workshop/))\n\n \n\n \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","embed-resources":true,"toc":true,"output-file":"01_textmining.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.532","editor":"visual","title":"Sentiment Analysis","author":[{"name":"John R Little","affiliations":[{"name":"Duke University"},{"department":"Center for Data & Vizualization Sciences"}]}],"date-modified":"today","date-format":"long","footer":"[John R Little](https://JohnLittle.info) ● [Center for Data & Visualization Sciences](https://library.duke.edu/data/) ● [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)","logo":"images/Rfun_logo.png","license":"CC BY","toc_float":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}